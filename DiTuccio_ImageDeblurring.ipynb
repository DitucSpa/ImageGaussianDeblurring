{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URtOslJ-jjzz"
      },
      "source": [
        "**GIANLUCA DI TUCCIO, EXAM 10-06-2022, IMAGE GAUSSIAN DEBLURRING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl4jwqEvikZw"
      },
      "source": [
        "# INTRODUCTION"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Model: Modified DnCNN + SRCNN<br>\n",
        "Test Set MSE: 0.0021539<br>\n",
        "Trainable Parameters: 215 k<br>\n",
        "Epochs: 70<br>\n",
        "Optimizer: Adam\n",
        "\n"
      ],
      "metadata": {
        "id": "k1No55WR-1Yw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW9tD9CdbH4N"
      },
      "source": [
        "The main task is to solve the noise and the gaussian blur in an image. Besides, it is also important to remember that it's impossible to obtain the original image from the blurred one, because after the blurring some original data are lost. For this task, I have preferred to use a simple/fast architecture than complex models that already exist, using the least number of parameters.<br>\n",
        "I use the [DnCNN](https://www.researchgate.net/publication/306187437_Beyond_a_Gaussian_Denoiser_Residual_Learning_of_Deep_CNN_for_Image_Denoising) (Denoising Convolutional Neural Networks) model for the denoising, proposed by the Harbin Institute of Technology and The Hong Kong Polytechnic University, and [SRCNN](https://arxiv.org/abs/1501.00092) (Super-Resolution) for deblurring the image. From these models, I add and modify some parts for adapting the entire model to our dataset (32x32x3 images), such as the number of layers, the size of filters, Subtract layer, etc, with all the considerations regarding these parts.<br>\n",
        "However, there are different type of blur (subject movement, camera movement, out of focus, etc) and it exists different model, such as:\n",
        "- DeepDeblur;\n",
        "- PSS-NSC;\n",
        "- MT-RNN;\n",
        "- MIMO-UNet.<br>\n",
        "\n",
        "The paper Rethinking Coarse-to-Fine Approach in Single Image Deblurring, Sung-Jin Cho, 2021, proposes some of these (https://arxiv.org/pdf/2108.05054.pdf).<br><br>\n",
        "Recommended articles: \n",
        "- [SRCNN Paper Summary & Implementation, Sieun Park, 2021](https://medium.com/analytics-vidhya/srcnn-paper-summary-implementation-ad5cea22a90e)\n",
        "- [Noise removal in images using deep learning models, Sunil Belde, 2021](https://medium.com/analytics-vidhya/noise-removal-in-images-using-deep-learning-models-3972544372d2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1RnLx4qjMuAQ"
      },
      "outputs": [],
      "source": [
        "# Library\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf \n",
        "import random\n",
        "from cv2 import GaussianBlur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFtM3iwkipvJ"
      },
      "source": [
        "# GET DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OO_ZsN9fMymB"
      },
      "outputs": [],
      "source": [
        "def getDataset():\n",
        "  (x_train, _), (x_test, _) = tf.keras.datasets.cifar10.load_data()\n",
        "  normalize = lambda x: x/x.max()\n",
        "  x_train = normalize(x_train)\n",
        "  x_test = normalize(x_test)\n",
        "  createBlurred = lambda arr: np.array([GaussianBlur(x, (5,5), ((random.random()*3)+1)) + (0.02*np.random.normal(0,1, (32, 32, 3))) for x in arr])\n",
        "  return (createBlurred(x_train), x_train), (createBlurred(x_test), x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SCwhPYJ8M1Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c602b98-6406-401b-dbfa-5e4a6cb962aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "train, test = getDataset()\n",
        "\n",
        "# get the train part (subdivided into noise and target)\n",
        "train_noise = train[0]\n",
        "train_target = train[1]\n",
        "\n",
        "# get the test part (subdivided into noise and target)\n",
        "test_noise = test[0]\n",
        "test_target = test[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRJc8v3L8vjn"
      },
      "source": [
        "# DnCNN\n",
        "![1](https://raw.githubusercontent.com/DitucSpa/ImageGaussianDeblurring/main/Images/DnCNN.png)\n",
        "<br>\n",
        "Given a noisy image, the model tries to predict the residual image (as shown in the upper image). It's composed by:\n",
        "- the first layer with Conv + ReLu of 64 filters 3x3;\n",
        "- a series of Conv + Batch Normalization + ReLu, 64 filters 3x3 for layer.\n",
        "- the last layer with only the Conv of 3 filters 1x1.\n",
        "<br>\n",
        "\n",
        "This model works both for gray and color image.<br>\n",
        "From this, we can obtein a denoise image using the Residual Learning, as:<br>\n",
        "Clean Image = Subtract(Noise Image - Predicted Residual Image).\n",
        "![1](https://raw.githubusercontent.com/DitucSpa/ImageGaussianDeblurring/main/Images/residual_learning.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SRCNN\n",
        "![1](https://raw.githubusercontent.com/DitucSpa/ImageGaussianDeblurring/main/Images/srcnn.png)\n",
        "\n",
        "\n",
        "The SRCNN is a model for image super-resolution. It's subdivided into three path:\n",
        "- patch extraction and representation;\n",
        "- non linear mapping (for introducing more non-linearity to improve theaccuracy);\n",
        "- reconstruction.\n",
        "This model is also used for deblurring an image."
      ],
      "metadata": {
        "id": "TOZXuGS4IklU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLsqGeoFrWvn"
      },
      "source": [
        "# FIND THE BEST CONFIGURATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT4oq7mj84rn"
      },
      "source": [
        "Before the fit of the model, it's important to choose the best configuration for the model (such as number of layers in the middle, filter dimension, number of filters, and so on). <br><br>\n",
        "!!! IMPORTANT NOTE!!!<br>\n",
        "For all the configurations, the SRCNN part (for deblurring) has remained the same, because there have not been important improvements. So, I have decided to change (and semplify) only the DnCNN part, with important improvements on the result. The follow blocks explain what to change for adapting the model to the our datast (32x32x3). I have also tried to use the least number of parameters, for a simply and fast model for the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXekLDLGu9xW"
      },
      "source": [
        "**DnCNN: NUMBER OF FILTERS PER LAYER**<br>\n",
        "First, I evaluate the model with different configurations for finding the better configuration. All the results were achieved using some fixed parameters, such as:\n",
        "- 10 levels for the loop (10 layers of CNN + BN + ReLu);\n",
        "- 3x3 filter dimension;\n",
        "- \"same\" padding;\n",
        "- 1 as stride;\n",
        "- 100 as batches size;\n",
        "- adam optimizer;\n",
        "- same SRCNN\n",
        "- 30 epochs.\n",
        "<br>\n",
        "\n",
        "The results are:\n",
        "![1](https://raw.githubusercontent.com/DitucSpa/ImageGaussianDeblurring/main/Images/ResultsWithDifferentFilter.png)\n",
        "The results for 10 layers with 128 filters (or 8 filters) for each level are not shown, because the performances were really bad (128 filters were too many for this dataset with 32x32x3 images, while 8 were too few).<br>\n",
        "The highlighted yellow rows show the best configuration:\n",
        "- the configuration with the lowest MSE with only 64 filters per layer (with high parameters) --> MSE = 0.0024 with 402.0k parameters;\n",
        "- the configuration with a good MSE with 32-64 filters per layer alternated (es: 64-32-64-32 and so on) --> MSE = 0.0025 with 215.1k parameters.\n",
        "\n",
        "However, given that the MSE for the 32-64 alternated configuration is near to the MSE of the 64 filters configuration, the 32-64 configuration could be better than other configurations, because this configuration uses half of the parameters than the 64 filters per layer configuration. Indeed, I will evaluate both configurations.\n",
        "<br>\n",
        "Besides, there's another configuration (highlighted in blue) that shows the configuration with the lowest parameters (but the MSE is not optimal)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ7qHPEP1lF5"
      },
      "source": [
        "**DnCNN: FILTER SIZE**<br>\n",
        "Besides, another paper has proposed a different architecture (autoencoder) with a 2x2 filter size (https://github.com/done-n-dusted/deblur-fashionmnist) with stride=1, because of the dataset (*fashionmnist*) with a 28x28x1 image dimension. As you can imagine, the *fashionmnist* dataset has images with 1 channel color instead of our 3 channel colors, thus the 2x2 filter size may not be enough (choosing odd kernel sizes has the benefit that we can preserve the spatial dimensionality). Indeed, the results were (with the same parameters as before, tested only for 32 filters per layer and 32-64 alternated):\n",
        "![2](https://raw.githubusercontent.com/DitucSpa/ImageGaussianDeblurring/main/Images/ResultsWithDifferentFilterSize.png)\n",
        "For the 16 filters per layers and the 16-32 alternated, the results were worse than before, thus the results are not reported in the table. Also, with the same results I choose the model with less parameters.<br>\n",
        "The 5x5 filter size achieves the better MSE for 32-64 alternated, but with 546.2k parameters, while the 3x3 filter size was close to the 5x5 MSE with only 215.5k parameters. Thus, I decide to use filters with a 3x3 size. Also, the 3x3 - 64 filters configuration achieves the same result (0.0024) using fewer parameters (402.0k instead of 546.2k).\n",
        "However, I have seen that using a 5x5 filter size for the first and last convolution and the others with a 3x3 filter size, the results were better 4 times out 5. Indeed, kernels with a large size can be helpful for incorporating information with large receptive fields, but two successive layers can increase the receptive field, mitigating this advantage.\n",
        "![3](https://raw.githubusercontent.com/DitucSpa/ImageGaussianDeblurring/main/Images/DnCNN_5Filters.png)\n",
        "<br><br>\n",
        "(The images below show accuracy rate and the processing time using different filter size, for differenti input image: 66x50, 90x75 and 132x100. The results show an equal behaviour of the filter size in different input image. Paper: Analysis of Filter Size Effect In Deep Learning, Yunus Camgözlü, 2020, https://arxiv.org/pdf/2101.01115.pdf).\n",
        "This is also explained by the type of images (32x32x3) that I use for the exam and for the purpose (gaussian deblurring).\n",
        "![4](https://raw.githubusercontent.com/DitucSpa/ImageGaussianDeblurring/main/Images/BatchSizePaper2.png)\n",
        "![5](https://raw.githubusercontent.com/DitucSpa/ImageGaussianDeblurring/main/Images/BatchSizePaper.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgoWx3YG77L2"
      },
      "source": [
        "**DnCNN: NUMBER OF LAYERS (CNN + BN + RELU)**<br>\n",
        "At the end, I try with different number of layers, but the results were worse than the 10 layers in the middle (same MSE with more parameters or worse MSE). Besides, I try to add some addition but without an important increase of performance, like the Squeezy and Excitation (code proposed by https://github.com/titu1994/keras-squeeze-excite-network) and some 1x1 Convolutional for reducing the depth numbers in the middle.<br>\n",
        "Also another [paper](https://arxiv.org/pdf/1705.03122.pdf) proposes some considerations regarding the number of filters and the number of layers (even if the paper have used Autoencoder, but the results were the same). Indeed, the more the layers, the lower the accuracy (or MSE) for bigger filter size. But, this inverse correlation isn't very large, so using small filter size and few number of layers is a better choise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVAdV2Q58frx"
      },
      "source": [
        "**CONCLUSION**<br>\n",
        "In conclusion, the configurations choosen for the model are:\n",
        "- 10 layers in the middle (CNN + BN + LReLU);\n",
        "- 3x3 filter dimension for the middle layers;\n",
        "- 5x5 filter dimension for the first and last convolution;\n",
        "- 1 as stride;\n",
        "- \"same\" padding;\n",
        "- 30 epochs;\n",
        "- adam optimazers;\n",
        "- 32 and 64 filters per layer in the middle architecture or 64 filters per layer;\n",
        "- same SRCNN.\n",
        "<br>\n",
        "\n",
        "Besides, there have been better results using [Leaky ReLu](https://keras.io/api/layers/activation_layers/leaky_relu/) (it fixes the “dying ReLU” problem --> it doesn’t have the zero-slope part) and a tanh actvivation in the first layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nElxD-mUM5C6",
        "outputId": "63f1dad5-7a31-4102-9e25-64e265657e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"DiTuccio_Modified_DnCNN\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " InputLayer (InputLayer)        [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " DnCNN_FirstConvLayer (Conv2D)  (None, 32, 32, 32)   2432        ['InputLayer[0][0]']             \n",
            "                                                                                                  \n",
            " DnCNN_FirstActivation_tanh (Ac  (None, 32, 32, 32)  0           ['DnCNN_FirstConvLayer[0][0]']   \n",
            " tivation)                                                                                        \n",
            "                                                                                                  \n",
            " DnCNN_0_64 (Conv2D)            (None, 32, 32, 64)   18496       ['DnCNN_FirstActivation_tanh[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " DnCNN_0_BN (BatchNormalization  (None, 32, 32, 64)  256         ['DnCNN_0_64[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " DnCNN_0_Activation_LeakyReLu (  (None, 32, 32, 64)  0           ['DnCNN_0_BN[0][0]']             \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " DnCNN_1_32 (Conv2D)            (None, 32, 32, 32)   18464       ['DnCNN_0_Activation_LeakyReLu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " DnCNN_1_BN (BatchNormalization  (None, 32, 32, 32)  128         ['DnCNN_1_32[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " DnCNN_1_Activation_LeakyReLu (  (None, 32, 32, 32)  0           ['DnCNN_1_BN[0][0]']             \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " DnCNN_2_64 (Conv2D)            (None, 32, 32, 64)   18496       ['DnCNN_1_Activation_LeakyReLu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " DnCNN_2_BN (BatchNormalization  (None, 32, 32, 64)  256         ['DnCNN_2_64[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " DnCNN_2_Activation_LeakyReLu (  (None, 32, 32, 64)  0           ['DnCNN_2_BN[0][0]']             \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " DnCNN_3_32 (Conv2D)            (None, 32, 32, 32)   18464       ['DnCNN_2_Activation_LeakyReLu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " DnCNN_3_BN (BatchNormalization  (None, 32, 32, 32)  128         ['DnCNN_3_32[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " DnCNN_3_Activation_LeakyReLu (  (None, 32, 32, 32)  0           ['DnCNN_3_BN[0][0]']             \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " DnCNN_4_64 (Conv2D)            (None, 32, 32, 64)   18496       ['DnCNN_3_Activation_LeakyReLu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " DnCNN_4_BN (BatchNormalization  (None, 32, 32, 64)  256         ['DnCNN_4_64[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " DnCNN_4_Activation_LeakyReLu (  (None, 32, 32, 64)  0           ['DnCNN_4_BN[0][0]']             \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " DnCNN_5_32 (Conv2D)            (None, 32, 32, 32)   18464       ['DnCNN_4_Activation_LeakyReLu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " DnCNN_5_BN (BatchNormalization  (None, 32, 32, 32)  128         ['DnCNN_5_32[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " DnCNN_5_Activation_LeakyReLu (  (None, 32, 32, 32)  0           ['DnCNN_5_BN[0][0]']             \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " DnCNN_6_64 (Conv2D)            (None, 32, 32, 64)   18496       ['DnCNN_5_Activation_LeakyReLu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " DnCNN_6_BN (BatchNormalization  (None, 32, 32, 64)  256         ['DnCNN_6_64[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " DnCNN_6_Activation_LeakyReLu (  (None, 32, 32, 64)  0           ['DnCNN_6_BN[0][0]']             \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " DnCNN_7_32 (Conv2D)            (None, 32, 32, 32)   18464       ['DnCNN_6_Activation_LeakyReLu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " DnCNN_7_BN (BatchNormalization  (None, 32, 32, 32)  128         ['DnCNN_7_32[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " DnCNN_7_Activation_LeakyReLu (  (None, 32, 32, 32)  0           ['DnCNN_7_BN[0][0]']             \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " DnCNN_8_64 (Conv2D)            (None, 32, 32, 64)   18496       ['DnCNN_7_Activation_LeakyReLu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " DnCNN_8_BN (BatchNormalization  (None, 32, 32, 64)  256         ['DnCNN_8_64[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " DnCNN_8_Activation_LeakyReLu (  (None, 32, 32, 64)  0           ['DnCNN_8_BN[0][0]']             \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " DnCNN_9_32 (Conv2D)            (None, 32, 32, 32)   18464       ['DnCNN_8_Activation_LeakyReLu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " DnCNN_9_BN (BatchNormalization  (None, 32, 32, 32)  128         ['DnCNN_9_32[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " DnCNN_9_Activation_LeakyReLu (  (None, 32, 32, 32)  0           ['DnCNN_9_BN[0][0]']             \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " DnCNN_LastConvLayer (Conv2D)   (None, 32, 32, 3)    2403        ['DnCNN_9_Activation_LeakyReLu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " DnCNN_SubtractLayer (Subtract)  (None, 32, 32, 3)   0           ['InputLayer[0][0]',             \n",
            "                                                                  'DnCNN_LastConvLayer[0][0]']    \n",
            "                                                                                                  \n",
            " SRCNN_9x9_Layer (Conv2D)       (None, 32, 32, 64)   15616       ['DnCNN_SubtractLayer[0][0]']    \n",
            "                                                                                                  \n",
            " SRCNN_1x1_Layer (Conv2D)       (None, 32, 32, 64)   4160        ['SRCNN_9x9_Layer[0][0]']        \n",
            "                                                                                                  \n",
            " SRCNN_5x5_Layer (Conv2D)       (None, 32, 32, 3)    4803        ['SRCNN_1x1_Layer[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 216,134\n",
            "Trainable params: 215,174\n",
            "Non-trainable params: 960\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# library used\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, Activation, BatchNormalization, Subtract, PReLU, Add, Conv2DTranspose\n",
        "\n",
        "# input\n",
        "input_shape = train_noise[0].shape\n",
        "input = Input(shape=input_shape, name = \"InputLayer\")\n",
        "\n",
        "# all the filters are initialize with a \"random normal\", while bias with zero.\n",
        "# the padding is the same and the stride is equal to 1 (by default)\n",
        "\n",
        "\n",
        "# ---------------------DnCNNN---------------------\n",
        "# first layer of the DnCNN, with 32 5x5 filters\n",
        "dncnn = Conv2D(32, kernel_size=(5,5), kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", \n",
        "           padding=\"same\", name = \"DnCNN_FirstConvLayer\")(input)\n",
        "dncnn = Activation(\"tanh\", name = \"DnCNN_FirstActivation_tanh\")(dncnn)\n",
        "\n",
        "# middle layers (10 levels) --> 64-32-64-32-etc\n",
        "for i in range(10):\n",
        "  if i%2 == 0:\n",
        "    dncnn = Conv2D(64, kernel_size=(3,3), kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", \n",
        "               padding=\"same\", name = f\"DnCNN_{i}_64\")(dncnn)\n",
        "    dncnn = BatchNormalization(axis=-1, name = f\"DnCNN_{i}_BN\")(dncnn)\n",
        "    dncnn = Activation(\"leaky_relu\", name = f\"DnCNN_{i}_Activation_LeakyReLu\")(dncnn)\n",
        "  else:\n",
        "    # or alternatively 64 insted of 32 for the model with all 64 filters per layer\n",
        "    dncnn = Conv2D(32, kernel_size=(3,3), kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", \n",
        "               padding=\"same\", name = f\"DnCNN_{i}_32\")(dncnn)\n",
        "    dncnn = BatchNormalization(axis=-1, name = f\"DnCNN_{i}_BN\")(dncnn)\n",
        "    dncnn = Activation(\"leaky_relu\", name = f\"DnCNN_{i}_Activation_LeakyReLu\")(dncnn)\n",
        "\n",
        "# last layer, 3 filters (for the RGB images) and 5x5 filter dimension\n",
        "dncnn = Conv2D(3, kernel_size=(5,5), kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", \n",
        "           padding=\"same\", name = \"DnCNN_LastConvLayer\")(dncnn)\n",
        "\n",
        "# subtract\n",
        "dncnn = Subtract(name = \"DnCNN_SubtractLayer\")([input, dncnn])\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------SRCNN---------------------\n",
        "srcnn = Conv2D(64, kernel_size=(9,9), kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", \n",
        "           padding=\"same\", activation=\"relu\", name = \"SRCNN_9x9_Layer\")(dncnn)\n",
        "srcnn = Conv2D(64, kernel_size=(1,1), kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", \n",
        "           padding=\"same\", activation=\"relu\", name = \"SRCNN_1x1_Layer\")(srcnn)\n",
        "srcnn = Conv2D(3, kernel_size=(5,5), kernel_initializer=\"random_normal\", bias_initializer=\"zeros\", \n",
        "           padding=\"same\", activation=\"relu\", name = \"SRCNN_5x5_Layer\")(srcnn)\n",
        "\n",
        "model = Model(input, srcnn, name = \"DiTuccio_Modified_DnCNN\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n-0sMSe_T7r"
      },
      "source": [
        "# SPLIT TRAIN, OPTIMIZER AND VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YJ9Dx1K-inK7"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "\n",
        "validation_split = 0.1 # the dataset is big, then 0.1 is enough\n",
        "\n",
        "# train\n",
        "train_for_fit = train_noise[:int(train_noise.shape[0]*(1-validation_split))]\n",
        "target_for_fit = train_target[:int(train_target.shape[0]*(1-validation_split))]\n",
        "\n",
        "# validation\n",
        "val_train = train_noise[-int(train_noise.shape[0]*validation_split):]\n",
        "val_target = train_target[-int(train_target.shape[0]*validation_split):]\n",
        "\n",
        "# learning rate (the learning rate is a hyperparameter --> this is the best configuration)\n",
        "# https://keras.io/api/callbacks/learning_rate_scheduler/\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 10:\n",
        "    return lr\n",
        "  elif epoch > 50:\n",
        "    return 0.00005\n",
        "  else:\n",
        "    return lr * 0.97\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "adam = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "model.compile(loss = 'mse', optimizer = adam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQGZvjvl_ZM5"
      },
      "source": [
        "# BATCH SIZE AS HYPERPARAMETER AND FIT OF THE MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the main purpose is to set the number of batch (as hyperparameter). The [paper](https://wandb.ai/ayush-thakur/dl-question-bank/reports/What-s-the-Optimal-Batch-Size-to-Train-a-Neural-Network---VmlldzoyMDkyNDU) shows that often the smaller the batch size the better the results (but also the computation time is worse). Also another [paper](https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e) proposes the same reasoning  using MNIST dataset.<br>\n",
        "Thus, I expect better result for small batch size (like 32 or 50) than big batch size (100, 200, 500), tested for 30 epochs.\n",
        "The table below shows the result achieved:\n",
        "![6](https://raw.githubusercontent.com/DitucSpa/ImageGaussianDeblurring/main/Images/BatchSize2.png)\n",
        "![7](https://raw.githubusercontent.com/DitucSpa/ImageGaussianDeblurring/main/Images/BatchSizeGraph2.png)\n",
        "\n",
        "At the end, the difference between the 32-64 alternated model and the 64 model isn't very large, so I've decided to use the first model, using only 215.5k parameters, with an appropriate LR and 70 epochs."
      ],
      "metadata": {
        "id": "ITpWBBm5jrdH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvXJnUSEM-QG",
        "outputId": "b810236e-58d6-45cf-ae6d-beffe43e67be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0064\n",
            "Epoch 1: val_loss improved from inf to 0.00396, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 44s 36ms/step - loss: 0.0064 - val_loss: 0.0040 - lr: 0.0010\n",
            "Epoch 2/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0036\n",
            "Epoch 2: val_loss improved from 0.00396 to 0.00347, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0036 - val_loss: 0.0035 - lr: 0.0010\n",
            "Epoch 3/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0031\n",
            "Epoch 3: val_loss improved from 0.00347 to 0.00305, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0031 - val_loss: 0.0030 - lr: 0.0010\n",
            "Epoch 4/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0029\n",
            "Epoch 4: val_loss improved from 0.00305 to 0.00284, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0029 - val_loss: 0.0028 - lr: 0.0010\n",
            "Epoch 5/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0028\n",
            "Epoch 5: val_loss improved from 0.00284 to 0.00271, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0028 - val_loss: 0.0027 - lr: 0.0010\n",
            "Epoch 6/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0027\n",
            "Epoch 6: val_loss improved from 0.00271 to 0.00269, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0027 - val_loss: 0.0027 - lr: 0.0010\n",
            "Epoch 7/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0026\n",
            "Epoch 7: val_loss improved from 0.00269 to 0.00255, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0026 - val_loss: 0.0026 - lr: 0.0010\n",
            "Epoch 8/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0026\n",
            "Epoch 8: val_loss did not improve from 0.00255\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0026 - val_loss: 0.0027 - lr: 0.0010\n",
            "Epoch 9/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0025\n",
            "Epoch 9: val_loss improved from 0.00255 to 0.00252, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0025 - val_loss: 0.0025 - lr: 0.0010\n",
            "Epoch 10/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0025\n",
            "Epoch 10: val_loss improved from 0.00252 to 0.00251, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0025 - val_loss: 0.0025 - lr: 0.0010\n",
            "Epoch 11/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0024\n",
            "Epoch 11: val_loss did not improve from 0.00251\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0024 - val_loss: 0.0026 - lr: 9.7000e-04\n",
            "Epoch 12/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0024\n",
            "Epoch 12: val_loss improved from 0.00251 to 0.00244, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0024 - val_loss: 0.0024 - lr: 9.4090e-04\n",
            "Epoch 13/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0024\n",
            "Epoch 13: val_loss improved from 0.00244 to 0.00242, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0024 - val_loss: 0.0024 - lr: 9.1267e-04\n",
            "Epoch 14/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0024\n",
            "Epoch 14: val_loss improved from 0.00242 to 0.00236, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0024 - val_loss: 0.0024 - lr: 8.8529e-04\n",
            "Epoch 15/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0023\n",
            "Epoch 15: val_loss did not improve from 0.00236\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0023 - val_loss: 0.0024 - lr: 8.5873e-04\n",
            "Epoch 16/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0023\n",
            "Epoch 16: val_loss improved from 0.00236 to 0.00235, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 8.3297e-04\n",
            "Epoch 17/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0023\n",
            "Epoch 17: val_loss improved from 0.00235 to 0.00232, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 8.0798e-04\n",
            "Epoch 18/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0023\n",
            "Epoch 18: val_loss did not improve from 0.00232\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 7.8374e-04\n",
            "Epoch 19/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0023\n",
            "Epoch 19: val_loss improved from 0.00232 to 0.00232, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 7.6023e-04\n",
            "Epoch 20/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0023\n",
            "Epoch 20: val_loss improved from 0.00232 to 0.00227, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 7.3742e-04\n",
            "Epoch 21/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0023\n",
            "Epoch 21: val_loss improved from 0.00227 to 0.00226, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 7.1530e-04\n",
            "Epoch 22/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0023\n",
            "Epoch 22: val_loss did not improve from 0.00226\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 6.9384e-04\n",
            "Epoch 23/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0023\n",
            "Epoch 23: val_loss did not improve from 0.00226\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 6.7303e-04\n",
            "Epoch 24/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 24: val_loss did not improve from 0.00226\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0022 - val_loss: 0.0024 - lr: 6.5284e-04\n",
            "Epoch 25/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 25: val_loss did not improve from 0.00226\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0022 - val_loss: 0.0023 - lr: 6.3325e-04\n",
            "Epoch 26/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 26: val_loss did not improve from 0.00226\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0023 - lr: 6.1425e-04\n",
            "Epoch 27/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 27: val_loss improved from 0.00226 to 0.00226, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0023 - lr: 5.9583e-04\n",
            "Epoch 28/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 28: val_loss improved from 0.00226 to 0.00225, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 5.7795e-04\n",
            "Epoch 29/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 29: val_loss improved from 0.00225 to 0.00223, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 5.6061e-04\n",
            "Epoch 30/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 30: val_loss did not improve from 0.00223\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 5.4379e-04\n",
            "Epoch 31/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 31: val_loss improved from 0.00223 to 0.00222, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 5.2748e-04\n",
            "Epoch 32/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 32: val_loss did not improve from 0.00222\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 5.1166e-04\n",
            "Epoch 33/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 33: val_loss did not improve from 0.00222\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 4.9631e-04\n",
            "Epoch 34/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 34: val_loss improved from 0.00222 to 0.00222, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 4.8142e-04\n",
            "Epoch 35/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 35: val_loss improved from 0.00222 to 0.00222, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 4.6697e-04\n",
            "Epoch 36/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 36: val_loss improved from 0.00222 to 0.00221, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 4.5297e-04\n",
            "Epoch 37/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 37: val_loss did not improve from 0.00221\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 4.3938e-04\n",
            "Epoch 38/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 38: val_loss did not improve from 0.00221\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 4.2620e-04\n",
            "Epoch 39/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 39: val_loss did not improve from 0.00221\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 4.1341e-04\n",
            "Epoch 40/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 40: val_loss improved from 0.00221 to 0.00220, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 4.0101e-04\n",
            "Epoch 41/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 41: val_loss improved from 0.00220 to 0.00219, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 3.8898e-04\n",
            "Epoch 42/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 42: val_loss did not improve from 0.00219\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 3.7731e-04\n",
            "Epoch 43/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 43: val_loss did not improve from 0.00219\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 3.6599e-04\n",
            "Epoch 44/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 44: val_loss did not improve from 0.00219\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 3.5501e-04\n",
            "Epoch 45/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 45: val_loss did not improve from 0.00219\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 3.4436e-04\n",
            "Epoch 46/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 46: val_loss did not improve from 0.00219\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 3.3403e-04\n",
            "Epoch 47/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 47: val_loss improved from 0.00219 to 0.00218, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 3.2401e-04\n",
            "Epoch 48/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 48: val_loss did not improve from 0.00218\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 3.1429e-04\n",
            "Epoch 49/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 49: val_loss improved from 0.00218 to 0.00218, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 3.0486e-04\n",
            "Epoch 50/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 50: val_loss did not improve from 0.00218\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 2.9571e-04\n",
            "Epoch 51/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 51: val_loss did not improve from 0.00218\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 2.8684e-04\n",
            "Epoch 52/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 52: val_loss improved from 0.00218 to 0.00216, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 53/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 53: val_loss improved from 0.00216 to 0.00216, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 54/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 54: val_loss did not improve from 0.00216\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 55/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 55: val_loss did not improve from 0.00216\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 56/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 56: val_loss did not improve from 0.00216\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 57/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 57: val_loss did not improve from 0.00216\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 58/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 58: val_loss did not improve from 0.00216\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 59/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 59: val_loss improved from 0.00216 to 0.00215, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 60/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 60: val_loss did not improve from 0.00215\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 61/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 61: val_loss improved from 0.00215 to 0.00215, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 62/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 62: val_loss did not improve from 0.00215\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 63/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 63: val_loss did not improve from 0.00215\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 64/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 64: val_loss did not improve from 0.00215\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 65/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 65: val_loss did not improve from 0.00215\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 66/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 66: val_loss did not improve from 0.00215\n",
            "900/900 [==============================] - 32s 36ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 67/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 67: val_loss did not improve from 0.00215\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 68/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 68: val_loss improved from 0.00215 to 0.00215, saving model to dituccio_model.hdf5\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 69/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 69: val_loss did not improve from 0.00215\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n",
            "Epoch 70/70\n",
            "899/900 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 70: val_loss did not improve from 0.00215\n",
            "900/900 [==============================] - 32s 35ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# save model using callback\n",
        "check_model_callback = ModelCheckpoint(filepath = \"dituccio_model.hdf5\", monitor=\"val_loss\", verbose=1, save_best_only=True, \n",
        "                             save_weights_only=True, mode=\"auto\", save_freq=\"epoch\")\n",
        "\n",
        "# fit of the model\n",
        "history = model.fit(train_for_fit, target_for_fit, batch_size=50, epochs=70, \n",
        "                    shuffle=True, validation_data=(val_train, val_target),\n",
        "                    callbacks=[check_model_callback, callback], verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "b1oDDa1CycUN"
      },
      "outputs": [],
      "source": [
        "def display_history(history):\n",
        "    mse_training = history.history['loss']\n",
        "    mse_val = history.history['val_loss']\n",
        "    plt.plot(mse_training)\n",
        "    plt.plot(mse_val)\n",
        "    plt.grid()\n",
        "    plt.title('Loss during training')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "OoiHzu2zyffl",
        "outputId": "37dcfbce-3d6d-4980-a44a-fe311e4ae4bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "display_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vMW3mb_22wz"
      },
      "source": [
        "# LOAD THE WEIGHTS AND RE-EVALUATE THE MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The performance on the test set is practically the same (no overfitting; there is a slight difference at the end, but it's very small). Also the dataset is big and for this model (DnCNN + SRCNN), data augmentation is not needed."
      ],
      "metadata": {
        "id": "okJAyHdyivqi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUL3o_PP--3Z",
        "outputId": "30839943-d2ae-42ae-aa20-d2bf99e11e45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 4s - loss: 0.0022 - 4s/epoch - 13ms/step\n",
            "The MSE for the test set is:\t0.002153907436877489\n"
          ]
        }
      ],
      "source": [
        "# load the model\n",
        "checkpoint_path = \"dituccio_model.hdf5\"\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "# test set\n",
        "score = model.evaluate(test_noise, test_target, verbose=2)\n",
        "print(f\"The MSE for the test set is:\\t{score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkUQDP-Wid9i"
      },
      "source": [
        "# IMAGE RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image_results(number_of_image):\n",
        "  fig = plt.figure(figsize=(12, 12))\n",
        "\n",
        "  # noise image\n",
        "  fig.add_subplot(1, 3, 1)\n",
        "  plt.imshow(test_noise[number_of_image])\n",
        "  plt.title(\"Noise Image\")\n",
        "\n",
        "  # original image\n",
        "  fig.add_subplot(1, 3, 2)\n",
        "  plt.imshow(test_target[number_of_image])\n",
        "  plt.title(\"Original Image\")\n",
        "\n",
        "  # Modified DnCNN\n",
        "  fig.add_subplot(1, 3, 3)\n",
        "  pred = model.predict(test_noise[number_of_image].reshape(-1, 32, 32, 3))\n",
        "  plt.imshow(pred[0])\n",
        "  plt.title(\"Modified DnCNN\")\n",
        "\n",
        "  plt.show()\n",
        "  "
      ],
      "metadata": {
        "id": "8OHKCtW4n3NJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_image_results(10)"
      ],
      "metadata": {
        "id": "sV4qZsqXnoeM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "bba88f3a-912f-48f5-d9b5-62f620ee4dba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x864 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DiTuccio_ImageDeblurring.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}